{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0aaa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.echogram import DataReaderZarr, get_data_readers\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import dask\n",
    "\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': False})\n",
    "\n",
    "#  Path to surveys\n",
    "survey_path = '/data/'\n",
    "\n",
    "#  Get list of relevant surveys\n",
    "surveys = ['2019/S2019847/ACOUSTIC/GRIDDED/S2019847_sv.zarr']\n",
    "readers = [DataReaderZarr(survey_path + zarr_file) for zarr_file in surveys]\n",
    "\n",
    "# Or alternatively ...\n",
    "# readers = get_data_readers()\n",
    "\n",
    "patch_size = (256, 256)  # x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1752cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = readers[0]\n",
    "\n",
    "n_pings, n_range = survey.shape\n",
    "\n",
    "xs = np.arange(patch_size[0] // 2, n_pings - patch_size[0] // 2, patch_size[0])\n",
    "ys = np.arange(patch_size[1] // 2, patch_size[1] * 3 - patch_size[1] // 2, patch_size[1])\n",
    "\n",
    "(xs, ys) = np.meshgrid(xs, ys)\n",
    "coordinate_list = np.array([xs.ravel(), ys.ravel()]).T[:-2,:] # Last two rows excluded\n",
    "\n",
    "fish_categories = list(survey.fish_categories)\n",
    "\n",
    "# x, y, mean, median, n_pixels_below_seabed, Nr of fish categories + ignore + background\n",
    "data = np.zeros((len(coordinate_list), 2 + 3 + len(survey.fish_categories) + 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a58225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 1186/31128 [36:43<14:11:34,  1.71s/it]"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in tqdm(enumerate(coordinate_list), total=len(coordinate_list)):\n",
    "    data[i, 0] = x\n",
    "    data[i, 1] = y\n",
    "\n",
    "    data_sv = survey.get_data_slice(idx_ping=x - patch_size[0] // 2, n_pings=patch_size[0],\n",
    "                                    idx_range=int(y - patch_size[1] // 2), n_range=patch_size[1],\n",
    "                                    return_numpy=False, frequencies=[38000])\n",
    "    mean_sv = data_sv.mean().values\n",
    "    median_sv = data_sv.median(dim=['ping_time', 'range']).values\n",
    "\n",
    "    data[i, 2] = mean_sv # Mean sv value\n",
    "    data[i, 3] = median_sv # Median sv value\n",
    "\n",
    "    seabed_mask = survey.get_seabed_mask(idx_ping=x - patch_size[0] // 2, n_pings=patch_size[0],\n",
    "                                         idx_range=int(y - patch_size[1] // 2), n_range=patch_size[1],\n",
    "                                         return_numpy=False)\n",
    "    n_pixels_below_seabed = seabed_mask.sum().values\n",
    "    data[i, 4] = n_pixels_below_seabed  # Pixels under seabed\n",
    "\n",
    "    labels = survey.annotation.annotation[:, (x - patch_size[0] // 2):(x + patch_size[0] // 2),\n",
    "             int(y - patch_size[1] // 2):int(y + patch_size[1] // 2)]\n",
    "\n",
    "    # Number of Pixels\n",
    "    data[i, 5] = labels.sel(category=1).sum().values  # Other class\n",
    "    data[i, 6] = labels.sel(category=27).sum().values  # Sandeel class\n",
    "    data[i, 7] = labels.sel(category=6009).sum().values  # Possible Sandeel class\n",
    "    data[i, 8] = 256 * 256 - (data[i, 5] + data[i, 6] + data[i, 7])  # Background class\n",
    "\n",
    "    # Average Intensity Values\n",
    "    if data[i, 5] != 0: data[i, 9] = ((data_sv * labels.sel(category=1)).sum() / data[i, 5]).values  # Average Other sv\n",
    "    if data[i, 6] != 0: data[i, 10] = (\n",
    "            (data_sv * labels.sel(category=27)).sum() / data[i, 6]).values  # Average Sandeel sv\n",
    "    if data[i, 7] != 0: data[i, 11] = (\n",
    "            (data_sv * labels.sel(category=6009)).sum() / data[i, 7]).values  # Average Possible Sandeel sv\n",
    "    if data[i, 8] == 256 * 256:\n",
    "        data[i, 12] = mean_sv\n",
    "    else:\n",
    "        data[i, 12] = data_sv[0].values[np.logical_and(labels.sel(category=27).values != 1,\n",
    "                                                       labels.sel(category=1).values != 1,\n",
    "                                                       labels.sel(category=6009).values != 1)].sum() / data[\n",
    "                          i, 8]  # Average Background sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8202690",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['x', 'y', 'mean_sv', 'median_sv', \n",
    "         'nop_below_seabed', 'nop_other', 'nop_sandeel', 'nop_possandeel', 'nop_background',\n",
    "         'mean_other', 'mean_sandeel', 'mean_possandeel', 'mean_background']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
